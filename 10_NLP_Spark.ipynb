{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 81. Introdução ao Spark",
   "id": "4e92b4861c7a3ad1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Spark**\n",
    "> NPL com Spark\n",
    "> \n",
    "> Utilizando bibliotecas Nativas de ML do Spark\n",
    "> \n",
    "> Classificação: Spam\n",
    "\n",
    "**Como Utilizar Spark**\n",
    "> Instalar a versão Open Source\n",
    ">> https://spark.apache.org/\n",
    ">\n",
    "> Provedor em Nuvem\n",
    ">> AWS\n",
    ">>\n",
    ">> Azure\n",
    ">>\n",
    ">> Databricks\n",
    "\n",
    "**Databricks**\n",
    "> Dos criadores do Spark\n",
    ">\n",
    "> Community Edition\n",
    ">\n",
    "> https://community.cloud.databricks.com/login.html\n",
    "\n",
    "**Spark**\n",
    "> Ferramenta de processamento de dados distribuidos em clusters\n",
    "> \n",
    "> Roda em memória\n",
    "> \n",
    "> Veloz\n",
    "> \n",
    "> Escalável\n",
    "> \n",
    "> Particionável\n",
    ">\n",
    "> Escala horizontal - Cluster\n",
    ">\n",
    "> Replicação/Tolerância a Falha\n",
    "> \n",
    "> Particionamento\n",
    "\n",
    "**Spark vs Python, R ou Banco de Dados**\n",
    "> Custo computacional: CPU, Memória, Rede, Etc.\n",
    "> \n",
    "> Arquitetura voltada a processar dados.\n",
    "> \n",
    "> Melhor performance, porém não substitui o Python, SQL ou um SGBD.\n",
    "\n",
    "**Linguagens**\n",
    "> Scala.\n",
    "> \n",
    "> Java.\n",
    "> \n",
    "> Python.\n",
    "> \n",
    "> R.\n",
    "> \n",
    "> SQL.\n",
    "\n",
    "**Por que Spark?**\n",
    "> NLP são tarefas com alto custo computacional\n",
    "> \n",
    "> Spark tem alta performance pela sua natureza 'distribuida'.\n",
    "> \n",
    "> Com pyspark, tem-se tudo do Python+Spark.\n",
    "\n",
    "**Arquitetura e Componentes**\n",
    "> Machine Learning (Mlib).\n",
    "> \n",
    "> SQL (Spark SQL).\n",
    "> \n",
    "> Processamento em Streaming.\n",
    "> \n",
    "> Processamento de Grafos (GraphX).\n",
    "\n",
    "**Spark SQL**\n",
    "> Permite ler dados tabulares de várias fontes (CSV, Json, Parquet, Orc, etc).\n",
    "> \n",
    "> Pode usar sintaxe SQL.\n",
    "\n",
    "**Streaming: Spark Structured Streaming**\n",
    "> Dados estruturados.\n",
    "\n",
    "**Grafos acíclicos dirigidos**\n",
    "> O spark constrói gráficos acíclicos dirigidos.\n",
    "\n",
    "**Elementos**\n",
    "> SparkSession: Sessão.\n",
    "> \n",
    "> Aplication: Programa.\n",
    "\n",
    "**Transformações e Ações**\n",
    "> Um dataframe é imutável: traz tolerância a falha.\n",
    "> \n",
    "> Uma transformação gera um novo dataframe.\n",
    "> \n",
    "> O processamento de transformação de fato só ocorre quando há uma ação: Lazy evaluation.\n",
    "\n",
    "**Lazy Evaluation**\n",
    "> Filter\n",
    ">> Union\n",
    ">>> Sample\n",
    ">>>> Show\n",
    "\n"
   ],
   "id": "5b0136de735ac51c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 82. Etapas de Processamento",
   "id": "bfac07e2e0b38bd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "> Ingressar no Databricks\n",
    "> \n",
    "> Criar um Cluster\n",
    "> \n",
    "> Importar Dados e Criar Tabela\n",
    "> \n",
    "> Criar Notebook\n",
    "\n",
    "**Pipeline**\n",
    "> Importar módulos\n",
    "> \n",
    "> Criar sessão do Spark\n",
    "> \n",
    "> Criar dataframe do Spark\n",
    "> \n",
    "> Transformar variável dependente (category)\n",
    "> \n",
    "> Tokenizar\n",
    "> \n",
    "> Word2vec\n",
    "> \n",
    "> Dividir treino e teste\n",
    "> \n",
    "> Criar modelo RandomForest\n",
    "> \n",
    "> Prever dados de teste\n",
    "> \n",
    "> Avaliar Performance"
   ],
   "id": "7c873a762fc2a54b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 84. Pré-Processamento",
   "id": "6df71d44fce06aac"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import Tokenizer, StringIndexer, Word2Vec\n",
    "spark = SparkSession.builder.appName(\"NLP\").getOrCreate()"
   ],
   "id": "6d37f4212fbb9c8e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# spam = spark.sql(\"select * from spam\")\n",
    "\n",
    "spam = spark.read.csv(r\"D:\\Users\\Nayan Couto\\Cloud Drive\\Documentos\\Arquivos PDF, PPT, DOC\\CURSOS\\Processamento de Linguagem Natural\\NLP\\10_NLP_SPARK\\spam.csv\", inferSchema=True, header=True)"
   ],
   "id": "c67025f7f6ea8aa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#spam.show(10, truncate=False)\n",
    "spam.show(10)"
   ],
   "id": "dd446d01a8de9854",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "stringmodel = StringIndexer(inputCol=\"Category\", outputCol=\"CategoryIndex\")",
   "id": "6d3562352b139556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamnew = stringmodel.fit(spam).transform(spam)",
   "id": "f2b64fbf16f59071",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamnew.show(10)",
   "id": "ba32fe95705ffe19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "tokens = Tokenizer(inputCol=\"Message\", outputCol=\"MessageToken\")\n",
    "spamtoken = tokens.transform(spamnew)"
   ],
   "id": "7bd1e79c56918104",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamtoken.show(10)",
   "id": "566b43c0f33bba6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamtoken.select(\"MessageToken\").show(10,truncate=False)",
   "id": "3aca9f417e64dbeb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 85. Criando e Avaliando o Modelo",
   "id": "586606fd83903c74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Criar o objeto word2vec\n",
    "word2vec = Word2Vec(inputCol=\"MessageToken\", outputCol=\"Messagew2v\")\n",
    "\n",
    "# Criar o pipeline\n",
    "pipeline = Pipeline(stages=[word2vec])\n",
    "\n",
    "# Treinar o pipeline\n",
    "spamresult = pipeline.fit(spamtoken).transform(spamtoken)"
   ],
   "id": "c39511e102489507",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamresult.show(10)",
   "id": "f9aa610388b48318",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamresult.select(\"Messagew2v\").show(10, truncate=False)",
   "id": "8aea114a6fd76ff1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamTreino, spamTeste = spamresult.randomSplit([0.7,0.3])",
   "id": "3b3001924371d455",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamTreino.show(10)",
   "id": "6038240bf570cbd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "spamTeste.show(10)",
   "id": "8af7ab969f987c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "rf = RandomForestClassifier(labelCol=\"CategoryIndex\", featuresCol=\"Messagew2v\", numTrees=500)",
   "id": "af02091eb04d05c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "modelo = rf.fit(spamTreino)",
   "id": "b99b90ebf67be914",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "previsoes = modelo.transform(spamTeste)",
   "id": "270184829f082163",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "previsoes.show(10)",
   "id": "c12e1dcc733e2e6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "avaliar = BinaryClassificationEvaluator(rawPredictionCol=\"prediction\", labelCol=\"CategoryIndex\", metricName=\"areaUnderROC\")\n",
    "areaUnderRoc = avaliar.evaluate(previsoes)\n",
    "print(areaUnderRoc)"
   ],
   "id": "70c1fc0e1f4d3079"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Notebook Spark no databricks",
   "id": "8e5f60c9fa7401b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/1231607683567896/2083876346600474/7009669397555107/latest.html",
   "id": "7ab47658a697a85f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cef27ff6c417c18b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
